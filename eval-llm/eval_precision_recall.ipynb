{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c527da0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from difflib import SequenceMatcher\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a2cdcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df = pd.read_csv(\"./dataset_eval/Meta-Llama-3.2-3B-Instruct-lora-adapter-v4_output (8).csv\")\n",
    "gt_df = pd.read_csv(\"./dataset_eval/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cf20dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>model_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*   Domain: **B√°n l·∫ª**\\n*   Ch·ª©c nƒÉng: **Thanh...</td>\n",
       "      <td>&lt;think&gt;\\n## 1. CHAIN ‚Äã‚ÄãOF THOUGHT\\n\\n*   **Ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Domain: Retail\\nFunction: Add to Wishlist\\nDes...</td>\n",
       "      <td>&lt;think&gt;\\n## 1. CHAIN ‚Äã‚ÄãOF THOUGHT\\n\\n*   **Ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Domain: **B√°n l·∫ª**\\nCh·ª©c nƒÉng: **Th√™m v√†o gi·ªè ...</td>\n",
       "      <td>## 1. CHAIN ‚Äã‚ÄãOF THOUGHT\\n\\n* **Business Goal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*   Domain: **B√°n l·∫ª**\\n*   Ch·ª©c nƒÉng: **Th√™m ...</td>\n",
       "      <td>&lt;think&gt;\\n## 1. CHAIN ‚Äã‚ÄãOF THOUGHT\\n\\n*   **Bus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Domain: Retail\\nFunction: View Cart\\nDescripti...</td>\n",
       "      <td>&lt;think&gt;\\n## 1. CHAIN ‚Äã‚ÄãOF THOUGHT\\n\\n*   **Bus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  *   Domain: **B√°n l·∫ª**\\n*   Ch·ª©c nƒÉng: **Thanh...   \n",
       "1  Domain: Retail\\nFunction: Add to Wishlist\\nDes...   \n",
       "2  Domain: **B√°n l·∫ª**\\nCh·ª©c nƒÉng: **Th√™m v√†o gi·ªè ...   \n",
       "3  *   Domain: **B√°n l·∫ª**\\n*   Ch·ª©c nƒÉng: **Th√™m ...   \n",
       "4  Domain: Retail\\nFunction: View Cart\\nDescripti...   \n",
       "\n",
       "                                        model_output  \n",
       "0  <think>\\n## 1. CHAIN ‚Äã‚ÄãOF THOUGHT\\n\\n*   **Ana...  \n",
       "1  <think>\\n## 1. CHAIN ‚Äã‚ÄãOF THOUGHT\\n\\n*   **Ana...  \n",
       "2  ## 1. CHAIN ‚Äã‚ÄãOF THOUGHT\\n\\n* **Business Goal ...  \n",
       "3  <think>\\n## 1. CHAIN ‚Äã‚ÄãOF THOUGHT\\n\\n*   **Bus...  \n",
       "4  <think>\\n## 1. CHAIN ‚Äã‚ÄãOF THOUGHT\\n\\n*   **Bus...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0eeeee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clean_json_from_text(raw_text):\n",
    "    \"\"\"\n",
    "    Clean a single text block & extract JSON test case.\n",
    "    Improved version with better Chinese comma handling and nested JSON extraction.\n",
    "    \"\"\"\n",
    "\n",
    "    if pd.isna(raw_text):\n",
    "        return None\n",
    "\n",
    "    text = str(raw_text)\n",
    "\n",
    "    # 1) Remove code fences\n",
    "    text = re.sub(r\"```json|```\", \"\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # 2) Remove <think> blocks\n",
    "    # Remove <think>...</think> (c√≥ closing tag)\n",
    "    text = re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL | re.IGNORECASE)\n",
    "    # Remove <think>... (kh√¥ng c√≥ closing tag - x√≥a t·ª´ <think> ƒë·∫øn h·∫øt)\n",
    "    text = re.sub(r\"<think>.*\", \"\", text, flags=re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "    # 3) Find JSON blocks - s·ª≠ d·ª•ng stack ƒë·ªÉ t√¨m JSON block ƒë√∫ng nh·∫•t\n",
    "    def find_json_block(text):\n",
    "        \"\"\"T√¨m JSON block b·∫±ng c√°ch ƒë·∫øm braces\"\"\"\n",
    "        first_brace = text.find('{')\n",
    "        if first_brace == -1:\n",
    "            return None\n",
    "        \n",
    "        # S·ª≠ d·ª•ng stack ƒë·ªÉ t√¨m } cu·ªëi c√πng kh·ªõp v·ªõi { ƒë·∫ßu ti√™n\n",
    "        stack = []\n",
    "        in_string = False\n",
    "        escape_next = False\n",
    "        \n",
    "        for i in range(first_brace, len(text)):\n",
    "            char = text[i]\n",
    "            \n",
    "            if escape_next:\n",
    "                escape_next = False\n",
    "                continue\n",
    "            \n",
    "            if char == '\\\\':\n",
    "                escape_next = True\n",
    "                continue\n",
    "            \n",
    "            if char == '\"' and not escape_next:\n",
    "                in_string = not in_string\n",
    "                continue\n",
    "            \n",
    "            if in_string:\n",
    "                continue\n",
    "            \n",
    "            if char == '{':\n",
    "                stack.append(i)\n",
    "            elif char == '}':\n",
    "                if stack:\n",
    "                    stack.pop()\n",
    "                    if len(stack) == 0:  # ƒê√£ ƒë√≥ng t·∫•t c·∫£ braces\n",
    "                        return text[first_brace:i+1]\n",
    "        \n",
    "        # N·∫øu kh√¥ng t√¨m th·∫•y closing brace ƒë√∫ng, th·ª≠ t√¨m } cu·ªëi c√πng\n",
    "        last_brace = text.rfind('}', first_brace)\n",
    "        if last_brace != -1:\n",
    "            return text[first_brace:last_brace + 1]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    json_text = find_json_block(text)\n",
    "    if json_text is None:\n",
    "        return None\n",
    "    \n",
    "    # 4) Fix c√°c v·∫•n ƒë·ªÅ ph·ªï bi·∫øn trong JSON\n",
    "    \n",
    "    # 4.1) Thay th·∫ø d·∫•u ph·∫©y ti·∫øng Trung (Ôºå) b·∫±ng d·∫•u ph·∫©y ti·∫øng Anh (,)\n",
    "    # C·∫ßn c·∫©n th·∫≠n kh√¥ng thay trong string values\n",
    "    # C√°ch l√†m: thay th·∫ø t·∫•t c·∫£ Ôºå nh∆∞ng ch·ªâ khi kh√¥ng n·∫±m trong string\n",
    "    def replace_chinese_commas(text):\n",
    "        \"\"\"Thay th·∫ø d·∫•u ph·∫©y Trung Qu·ªëc nh∆∞ng kh√¥ng thay trong string values\"\"\"\n",
    "        result = []\n",
    "        in_string = False\n",
    "        escape_next = False\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(text):\n",
    "            char = text[i]\n",
    "            \n",
    "            if escape_next:\n",
    "                result.append(char)\n",
    "                escape_next = False\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            if char == '\\\\':\n",
    "                result.append(char)\n",
    "                escape_next = True\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            if char == '\"':\n",
    "                in_string = not in_string\n",
    "                result.append(char)\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            if char == 'Ôºå' and not in_string:\n",
    "                result.append(',')\n",
    "            else:\n",
    "                result.append(char)\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        return ''.join(result)\n",
    "    \n",
    "    json_text = replace_chinese_commas(json_text)\n",
    "    \n",
    "    # 4.2) X·ª≠ l√Ω escape characters (n·∫øu c·∫ßn)\n",
    "    # Th∆∞·ªùng kh√¥ng c·∫ßn v√¨ JSON parser t·ª± x·ª≠ l√Ω, nh∆∞ng n·∫øu c√≥ v·∫•n ƒë·ªÅ th√¨ th·ª≠\n",
    "    try:\n",
    "        # Th·ª≠ parse tr·ª±c ti·∫øp tr∆∞·ªõc\n",
    "        data = json.loads(json_text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        # N·∫øu l·ªói, th·ª≠ fix th√™m\n",
    "        # Lo·∫°i b·ªè trailing commas (d·∫•u ph·∫©y th·ª´a ·ªü cu·ªëi)\n",
    "        json_text = re.sub(r',\\s*}', '}', json_text)\n",
    "        json_text = re.sub(r',\\s*]', ']', json_text)\n",
    "        \n",
    "        # Th·ª≠ l·∫°i\n",
    "        try:\n",
    "            data = json.loads(json_text)\n",
    "        except json.JSONDecodeError as e2:\n",
    "            # N·∫øu v·∫´n l·ªói, th·ª≠ t√¨m JSON block kh√°c\n",
    "            # T√¨m t·∫•t c·∫£ c√°c JSON blocks c√≥ th·ªÉ\n",
    "            candidates = []\n",
    "            start = 0\n",
    "            while True:\n",
    "                start_brace = text.find('{', start)\n",
    "                if start_brace == -1:\n",
    "                    break\n",
    "                block = find_json_block(text[start_brace:])\n",
    "                if block:\n",
    "                    candidates.append(block)\n",
    "                start = start_brace + 1\n",
    "            \n",
    "            if candidates:\n",
    "                # Th·ª≠ t·ª´ng candidate, ch·ªçn c√°i parse ƒë∆∞·ª£c\n",
    "                for candidate in sorted(candidates, key=len, reverse=True):\n",
    "                    candidate = replace_chinese_commas(candidate)\n",
    "                    candidate = re.sub(r',\\s*}', '}', candidate)\n",
    "                    candidate = re.sub(r',\\s*]', ']', candidate)\n",
    "                    try:\n",
    "                        data = json.loads(candidate)\n",
    "                        json_text = candidate\n",
    "                        break\n",
    "                    except:\n",
    "                        continue\n",
    "                else:\n",
    "                    return None\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    # 5) Only keep what we need\n",
    "    cleaned_data = {\n",
    "        \"request_body\": data.get(\"request_body\", {}),\n",
    "        \"testcases\": data.get(\"testcases\", {})\n",
    "    }\n",
    "\n",
    "    # 6) Validate testcases structure, specifically response_mapping\n",
    "    # Ensure that `response_mapping` within any test case is a dictionary.\n",
    "    testcases = cleaned_data.get(\"testcases\")\n",
    "    if testcases:\n",
    "        for tc_type in [\"basic_validation\", \"business_logic\"]:\n",
    "            if tc_type in testcases and isinstance(testcases[tc_type], list):\n",
    "                for tc_entry in testcases[tc_type]:\n",
    "                    expected_output = tc_entry.get(\"expected_output\")\n",
    "                    if expected_output and \"response_mapping\" in expected_output:\n",
    "                        resp_mapping = expected_output[\"response_mapping\"]\n",
    "                        # Ch·ªâ validate n·∫øu response_mapping kh√¥ng ph·∫£i None v√† kh√¥ng ph·∫£i dict\n",
    "                        if resp_mapping is not None and not isinstance(resp_mapping, dict):\n",
    "                            # If response_mapping is not a dict (v√† kh√¥ng ph·∫£i None), consider this entire JSON invalid\n",
    "                            return None\n",
    "\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f50484f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒêang tr√≠ch xu·∫•t JSON t·ª´ model_output...\n",
      "\n",
      "üìä K·∫øt qu·∫£ tr√≠ch xu·∫•t:\n",
      "   - T·ªïng s·ªë records: 129\n",
      "   - Records c√≥ JSON h·ª£p l·ªá: 11\n",
      "   - Records kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c: 118\n",
      "   - T·ª∑ l·ªá th√†nh c√¥ng: 8.53%\n",
      "\n",
      "‚ö†Ô∏è  M·ªôt v√†i records kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c (index): [0, 1, 2]\n",
      "   B·∫°n c√≥ th·ªÉ ki·ªÉm tra model_output c·ªßa c√°c records n√†y ƒë·ªÉ debug.\n"
     ]
    }
   ],
   "source": [
    "# Extract JSON t·ª´ model_output\n",
    "print(\"ƒêang tr√≠ch xu·∫•t JSON t·ª´ model_output...\")\n",
    "pre_df[\"clean_output\"] = pre_df[\"model_output\"].apply(extract_clean_json_from_text)\n",
    "gt_df[\"clean_output\"] = gt_df[\"json_output\"].apply(extract_clean_json_from_text)\n",
    "\n",
    "# Ki·ªÉm tra k·∫øt qu·∫£\n",
    "print(f\"\\nüìä K·∫øt qu·∫£ tr√≠ch xu·∫•t:\")\n",
    "print(f\"   - T·ªïng s·ªë records: {len(pre_df)}\")\n",
    "print(f\"   - Records c√≥ JSON h·ª£p l·ªá: {pre_df['clean_output'].notna().sum()}\")\n",
    "print(f\"   - Records kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c: {pre_df['clean_output'].isna().sum()}\")\n",
    "print(f\"   - T·ª∑ l·ªá th√†nh c√¥ng: {pre_df['clean_output'].notna().sum() / len(pre_df) * 100:.2f}%\")\n",
    "\n",
    "# Hi·ªÉn th·ªã m·ªôt v√†i records kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c (n·∫øu c√≥)\n",
    "failed_indices = pre_df[pre_df['clean_output'].isna()].index[:3]\n",
    "if len(failed_indices) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  M·ªôt v√†i records kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c (index): {list(failed_indices)}\")\n",
    "    print(\"   B·∫°n c√≥ th·ªÉ ki·ªÉm tra model_output c·ªßa c√°c records n√†y ƒë·ªÉ debug.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bad007e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DEBUG RECORD #0\n",
      "============================================================\n",
      "\n",
      "üìù Model output (first 500 chars):\n",
      "<think>\\n## 1. CHAIN ‚Äã‚ÄãOF THOUGHT\\n\\n*   **Analyze Business Objectives:** \"FirstÔºå what does this API exist for? What is the main goal? (E.g.Ôºå 'Allow the user to create a new order'). Important assumptionsÔºå preconditions What is important? (For example: 'User must have admin rights'Ôºå 'Product must exist in stock').\"\\n    *   M·ª•c ti√™u ch√≠nh c·ªßa API n√†y l√† x·ª≠ l√Ω thanh to√°n cho m·ªôt ƒë∆°n h√†ng c·ª• th·ªÉ.\\n    *   C√°c gi·∫£ ƒë·ªãnh quan tr·ªçng l√† ƒë∆°n h√†ng (`orderId`) ph·∫£i t·ªìn t·∫°i v√† c√≥ tr·∫°ng th√°i h·ª£p l·ªá ƒë·ªÉ thanh\n",
      "...\n",
      "\n",
      "‚ùå Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c JSON\n",
      "\n",
      "‚úÖ T√¨m th·∫•y { ƒë·∫ßu ti√™n t·∫°i v·ªã tr√≠: 3577\n",
      "   Text xung quanh: ...rror case for an invalid order status.\\n</think>\\n{\\n  \"request_body\": {\\n    \"orderId\": \"ORD-2024-001\"Ôºå\\n    \"paymentMethodId\": \"PM-VISA-1234\"Ôºå\\n    \"amount\": 1500000Ôºå\\n    \"currency\": \"VND\"\\n  }Ôºå\\n  \"testcases\": {\\n    \"basic_validation\": [\\n      ...\n",
      "\n",
      "üìã JSON candidate (first 300 chars):\n",
      "{\\n  \"request_body\": {\\n    \"orderId\": \"ORD-2024-001\"Ôºå\\n    \"paymentMethodId\": \"PM-VISA-1234\"Ôºå\\n    \"amount\": 1500000Ôºå\\n    \"currency\": \"VND\"\\n  }Ôºå\\n  \"testcases\": {\\n    \"basic_validation\": [\\n      {\\n        \"test_case_id\": 1Ôºå\\n        \"test_case\": \"orderId with ABSENT should return statuscode 40\n",
      "...\n",
      "\n",
      "‚ùå JSON candidate kh√¥ng parse ƒë∆∞·ª£c: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "   L·ªói t·∫°i v·ªã tr√≠: 1\n",
      "   Context: ...{\\n  \"request_body\": {\\n    \"orderId\": \"ORD-2024-00...\n",
      "\n",
      "============================================================\n",
      "DEBUG RECORD #1\n",
      "============================================================\n",
      "\n",
      "üìù Model output (first 500 chars):\n",
      "<think>\\n## 1. CHAIN ‚Äã‚ÄãOF THOUGHT\\n\\n*   **Analyze Business Objectives:**\\n    *   **Main Goal:** To allow a logged-in user to add a product to their personal favorites list.\\n    *   **Preconditions/Assumptions:** The user must be authenticated and have an active session. The product must be a valid and active entity in the system's catalog.\\n\\n*   **Analyze Basic Validation (BV):**\\n    I will examine validation constraints for each field in the request body.\\n    *   - `userId`: (MandatoryÔºå S\n",
      "...\n",
      "\n",
      "‚ùå Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c JSON\n",
      "\n",
      "‚úÖ T√¨m th·∫•y { ƒë·∫ßu ti√™n t·∫°i v·ªã tr√≠: 2746\n",
      "   Text xung quanh: ...e (Rule 3)Ôºå and invalid user (Rule 4).\\n</think>\\n{\\n  \"request_body\": {\\n    \"userId\": \"usr_a1b2c3d4\"Ôºå\\n    \"productId\": \"prod_12345678\"Ôºå\\n    \"itemType\": \"PRODUCT\"Ôºå\\n    \"source\": \"PDP\"Ôºå\\n    \"notes\": \"Interested in the blue color.\"\\n  }Ôºå\\n  \"testc...\n",
      "\n",
      "üìã JSON candidate (first 300 chars):\n",
      "{\\n  \"request_body\": {\\n    \"userId\": \"usr_a1b2c3d4\"Ôºå\\n    \"productId\": \"prod_12345678\"Ôºå\\n    \"itemType\": \"PRODUCT\"Ôºå\\n    \"source\": \"PDP\"Ôºå\\n    \"notes\": \"Interested in the blue color.\"\\n  }Ôºå\\n  \"testcases\": {\\n    \"basic_validation\": [\\n      {\\n        \"test_case_id\": 1Ôºå\\n        \"test_case\": \"user\n",
      "...\n",
      "\n",
      "‚ùå JSON candidate kh√¥ng parse ƒë∆∞·ª£c: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "   L·ªói t·∫°i v·ªã tr√≠: 1\n",
      "   Context: ...{\\n  \"request_body\": {\\n    \"userId\": \"usr_a1b2c3d4...\n",
      "\n",
      "============================================================\n",
      "DEBUG RECORD #2\n",
      "============================================================\n",
      "\n",
      "üìù Model output (first 500 chars):\n",
      "## 1. CHAIN ‚Äã‚ÄãOF THOUGHT\\n\\n* **Business Goal Analysis:** \"FirstÔºå what does this API exist for? What is the main goal? (e.g.Ôºå 'Allow the user to create a new order'). Important assumptionsÔºå preconditions What is important? (For example: 'User must have admin rights'Ôºå 'Product must exist in stock').\"\\n\t+ M·ª•c ti√™u ch√≠nh: Cho ph√©p ng∆∞·ªùi d√πng th√™m m·ªôt s·∫£n ph·∫©m v√†o gi·ªè h√†ng.\\n\t+ Gi·∫£ ƒë·ªãnh/ƒëi·ªÅu ki·ªán ti√™n quy·∫øt: S·∫£n ph·∫©m ph·∫£i t·ªìn t·∫°i v√† ƒëang kinh doanh. Gi·ªè h√†ng ph·∫£i ƒë∆∞·ª£c x√°c ƒë·ªãnh b·ªüi `sessionId` (ƒë√£ ƒëƒÉ\n",
      "...\n",
      "\n",
      "‚ùå Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c JSON\n",
      "\n",
      "‚úÖ T√¨m th·∫•y { ƒë·∫ßu ti√™n t·∫°i v·ªã tr√≠: 5095\n",
      "   Text xung quanh: ...NUMS(n)`Ôºå `ALPHANUMS(n)`Ôºå `EMAIL(n)`.\\n\\n```json\\n{\\n  \"request_body\": {\\n    \"productId\": \"SKU-RUN-001\"Ôºå\\n    \"quantity\": 1Ôºå\\n    \"sessionId\": \"sess_a1b2c3d4-e5f6-7890-1234-567890abcdef\"\\n  }Ôºå\\n  \"testcases\": {\\n    \"basic_validation\": [\\n      {\\n ...\n",
      "\n",
      "üìã JSON candidate (first 300 chars):\n",
      "{\\n  \"request_body\": {\\n    \"productId\": \"SKU-RUN-001\"Ôºå\\n    \"quantity\": 1Ôºå\\n    \"sessionId\": \"sess_a1b2c3d4-e5f6-7890-1234-567890abcdef\"\\n  }Ôºå\\n  \"testcases\": {\\n    \"basic_validation\": [\\n      {\\n        \"test_case_id\": 1Ôºå\\n        \"test_case\": \"productId with ABSENT should return statuscode 400\"\n",
      "...\n",
      "\n",
      "‚ùå JSON candidate kh√¥ng parse ƒë∆∞·ª£c: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "   L·ªói t·∫°i v·ªã tr√≠: 1\n",
      "   Context: ...{\\n  \"request_body\": {\\n    \"productId\": \"SKU-RUN-0...\n"
     ]
    }
   ],
   "source": [
    "# Debug: Ki·ªÉm tra m·ªôt v√†i records th·∫•t b·∫°i\n",
    "import json\n",
    "\n",
    "def debug_extraction(idx):\n",
    "    \"\"\"Debug extraction cho m·ªôt record c·ª• th·ªÉ\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"DEBUG RECORD #{idx}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    model_output = pre_df.iloc[idx]['model_output']\n",
    "    print(f\"\\nüìù Model output (first 500 chars):\")\n",
    "    print(model_output[:500])\n",
    "    print(\"...\")\n",
    "    \n",
    "    # Th·ª≠ extract\n",
    "    result = extract_clean_json_from_text(model_output)\n",
    "    \n",
    "    if result is None:\n",
    "        print(\"\\n‚ùå Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c JSON\")\n",
    "        \n",
    "        # T√¨m { ƒë·∫ßu ti√™n\n",
    "        first_brace = model_output.find('{')\n",
    "        if first_brace != -1:\n",
    "            print(f\"\\n‚úÖ T√¨m th·∫•y {{ ƒë·∫ßu ti√™n t·∫°i v·ªã tr√≠: {first_brace}\")\n",
    "            print(f\"   Text xung quanh: ...{model_output[max(0, first_brace-50):first_brace+200]}...\")\n",
    "            \n",
    "            # Th·ª≠ t√¨m JSON block th·ªß c√¥ng\n",
    "            text = str(model_output)\n",
    "            text = re.sub(r\"```json|```\", \"\", text, flags=re.IGNORECASE)\n",
    "            text = re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL | re.IGNORECASE)\n",
    "            text = re.sub(r\"<think>.*\", \"\", text, flags=re.DOTALL | re.IGNORECASE)\n",
    "            \n",
    "            first_brace = text.find('{')\n",
    "            if first_brace != -1:\n",
    "                last_brace = text.rfind('}', first_brace)\n",
    "                if last_brace != -1:\n",
    "                    json_candidate = text[first_brace:last_brace + 1]\n",
    "                    print(f\"\\nüìã JSON candidate (first 300 chars):\")\n",
    "                    print(json_candidate[:300])\n",
    "                    print(\"...\")\n",
    "                    \n",
    "                    # Th·ª≠ parse\n",
    "                    try:\n",
    "                        # Thay d·∫•u ph·∫©y Trung Qu·ªëc\n",
    "                        json_candidate_fixed = json_candidate.replace('Ôºå', ',')\n",
    "                        data = json.loads(json_candidate_fixed)\n",
    "                        print(\"\\n‚úÖ JSON candidate c√≥ th·ªÉ parse ƒë∆∞·ª£c sau khi fix!\")\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"\\n‚ùå JSON candidate kh√¥ng parse ƒë∆∞·ª£c: {e}\")\n",
    "                        print(f\"   L·ªói t·∫°i v·ªã tr√≠: {e.pos}\")\n",
    "                        if e.pos:\n",
    "                            start = max(0, e.pos - 50)\n",
    "                            end = min(len(json_candidate_fixed), e.pos + 50)\n",
    "                            print(f\"   Context: ...{json_candidate_fixed[start:end]}...\")\n",
    "        else:\n",
    "            print(\"\\n‚ùå Kh√¥ng t√¨m th·∫•y { trong model_output\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ Tr√≠ch xu·∫•t th√†nh c√¥ng!\")\n",
    "        print(f\"   Keys: {list(result.keys())}\")\n",
    "        if 'testcases' in result:\n",
    "            testcases = result['testcases']\n",
    "            if isinstance(testcases, dict):\n",
    "                for key in testcases:\n",
    "                    if isinstance(testcases[key], list):\n",
    "                        print(f\"   {key}: {len(testcases[key])} test cases\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Debug 3 records ƒë·∫ßu ti√™n\n",
    "for idx in [0, 1, 2]:\n",
    "    debug_extraction(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "317e9fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df[\"request_body\"] = pre_df[\"clean_output\"].apply(lambda x: x.get(\"request_body\") if x else None)\n",
    "pre_df[\"testcases\"] = pre_df[\"clean_output\"].apply(lambda x: x.get(\"testcases\") if x else None)\n",
    "\n",
    "gt_df[\"request_body\"] = gt_df[\"clean_output\"].apply(lambda x: x.get(\"request_body\") if x else None)\n",
    "gt_df[\"testcases\"] = gt_df[\"clean_output\"].apply(lambda x: x.get(\"testcases\") if x else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "324f6981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 129 entries, 0 to 128\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   input         129 non-null    object\n",
      " 1   model_output  129 non-null    object\n",
      " 2   clean_output  11 non-null     object\n",
      " 3   request_body  11 non-null     object\n",
      " 4   testcases     11 non-null     object\n",
      "dtypes: object(5)\n",
      "memory usage: 5.2+ KB\n"
     ]
    }
   ],
   "source": [
    "pre_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99965e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df['testcases'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d68b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df['testcases'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a482cbb",
   "metadata": {},
   "source": [
    "# üìã C√ÅCH T√çNH TP, FP, FN D·ª∞A TR√äN MATCHING + PARTIAL MATCHING\n",
    "\n",
    "## 1. C√°c tr∆∞·ªùng h·ª£p t√≠nh TP, FP, FN\n",
    "\n",
    "### 1.1. Tr∆∞·ªùng h·ª£p Model JSON l·ªói (parse l·ªói)\n",
    "- **T·∫•t c·∫£ test cases trong GT** ‚Üí **FN**\n",
    "- **TP = 0, FP = 0, FN = s·ªë l∆∞·ª£ng test cases trong GT**\n",
    "\n",
    "### 1.2. Tr∆∞·ªùng h·ª£p Model c√≥ test case m√† GT kh√¥ng c√≥\n",
    "- **FP += 1**\n",
    "- Status: `'FP'`\n",
    "- Reason: `'Model has extra test case'`\n",
    "\n",
    "### 1.3. Tr∆∞·ªùng h·ª£p GT c√≥ test case m√† Model kh√¥ng c√≥\n",
    "- **FN += 1**\n",
    "- Status: `'FN'`\n",
    "- Reason: `'Model missing test case'`\n",
    "\n",
    "### 1.4. Tr∆∞·ªùng h·ª£p c·∫£ GT v√† Model ƒë·ªÅu c√≥ test case ‚Üí So s√°nh\n",
    "\n",
    "#### B∆∞·ªõc 1: T√≠nh similarity\n",
    "- S·ª≠ d·ª•ng h√†m `compare_cases(gt_case, model_case, similarity_threshold=0.85)`\n",
    "- Tr·∫£ v·ªÅ: `(is_match, similarity, field_details)`\n",
    "- `similarity`: gi√° tr·ªã t·ª´ 0.0 ƒë·∫øn 1.0\n",
    "\n",
    "#### B∆∞·ªõc 2: Ph√¢n lo·∫°i d·ª±a tr√™n similarity\n",
    "\n",
    "**a) Match ho√†n to√†n (is_match = True, similarity >= threshold)**\n",
    "- **TP += 1**\n",
    "- Status: `'TP'`\n",
    "- Reason: `'Match (similarity: X.XX)'`\n",
    "\n",
    "**b) Partial match (is_match = False, nh∆∞ng similarity >= 0.7)**\n",
    "- **TP += 0.5**\n",
    "- **FP += 0.5**\n",
    "- **FN += 0.5**\n",
    "- Status: `'PARTIAL'`\n",
    "- Reason: `'Partial match (similarity: X.XX)'`\n",
    "\n",
    "**c) Kh√¥ng match (is_match = False, similarity < 0.7)**\n",
    "- **FP += 1**\n",
    "- **FN += 1**\n",
    "- Status: `'FP+FN'`\n",
    "- Reason: `'Low similarity (similarity: X.XX)'`\n",
    "\n",
    "---\n",
    "\n",
    "## 2. C√¥ng th·ª©c t√≠nh Precision, Recall, F1\n",
    "\n",
    "Sau khi t√≠nh xong TP, FP, FN cho t·∫•t c·∫£ test cases trong 1 record:\n",
    "\n",
    "### 2.1. Precision (ƒê·ªô ch√≠nh x√°c)\n",
    "```\n",
    "Precision = TP / (TP + FP)\n",
    "```\n",
    "- **√ù nghƒ©a**: Trong s·ªë c√°c test case model d·ª± ƒëo√°n, bao nhi√™u l√† ƒë√∫ng?\n",
    "- **N·∫øu TP + FP = 0** ‚Üí Precision = 0.0\n",
    "\n",
    "### 2.2. Recall (ƒê·ªô bao ph·ªß)\n",
    "```\n",
    "Recall = TP / (TP + FN)\n",
    "```\n",
    "- **√ù nghƒ©a**: Trong s·ªë c√°c test case c·∫ßn c√≥, model t√¨m ƒë∆∞·ª£c bao nhi√™u?\n",
    "- **N·∫øu TP + FN = 0** ‚Üí Recall = 0.0\n",
    "\n",
    "### 2.3. F1 Score (C√¢n b·∫±ng Precision v√† Recall)\n",
    "```\n",
    "F1 = 2 √ó (Precision √ó Recall) / (Precision + Recall)\n",
    "```\n",
    "- **√ù nghƒ©a**: Harmonic mean c·ªßa Precision v√† Recall\n",
    "- **N·∫øu Precision + Recall = 0** ‚Üí F1 = 0.0\n",
    "\n",
    "---\n",
    "\n",
    "## 3. V√≠ d·ª• c·ª• th·ªÉ\n",
    "\n",
    "### V√≠ d·ª• 1: Record c√≥ 17 test cases\n",
    "\n",
    "**K·∫øt qu·∫£ so s√°nh:**\n",
    "- 8 test cases: TP (match ho√†n to√†n)\n",
    "- 8 test cases: FP+FN (similarity < 0.7)\n",
    "- 1 test case: FN (model thi·∫øu)\n",
    "\n",
    "**T√≠nh to√°n:**\n",
    "- TP = 8.0\n",
    "- FP = 8.0 (t·ª´ 8 test cases FP+FN)\n",
    "- FN = 9.0 (8 t·ª´ FP+FN + 1 t·ª´ missing)\n",
    "\n",
    "**Metrics:**\n",
    "- Precision = 8.0 / (8.0 + 8.0) = 0.5000\n",
    "- Recall = 8.0 / (8.0 + 9.0) = 0.4706\n",
    "- F1 = 2 √ó (0.5000 √ó 0.4706) / (0.5000 + 0.4706) = 0.4848\n",
    "\n",
    "### V√≠ d·ª• 2: Record c√≥ partial match\n",
    "\n",
    "**K·∫øt qu·∫£ so s√°nh:**\n",
    "- 5 test cases: TP (match ho√†n to√†n)\n",
    "- 3 test cases: PARTIAL (similarity >= 0.7 nh∆∞ng < 0.85)\n",
    "- 2 test cases: FP+FN (similarity < 0.7)\n",
    "- 1 test case: FN (model thi·∫øu)\n",
    "\n",
    "**T√≠nh to√°n:**\n",
    "- TP = 5.0 + (3 √ó 0.5) = 6.5\n",
    "- FP = (3 √ó 0.5) + 2.0 = 3.5\n",
    "- FN = (3 √ó 0.5) + 2.0 + 1.0 = 4.5\n",
    "\n",
    "**Metrics:**\n",
    "- Precision = 6.5 / (6.5 + 3.5) = 0.6500\n",
    "- Recall = 6.5 / (6.5 + 4.5) = 0.5909\n",
    "- F1 = 2 √ó (0.6500 √ó 0.5909) / (0.6500 + 0.5909) = 0.6190\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Ng∆∞·ª°ng similarity\n",
    "\n",
    "- **similarity_threshold = 0.85**: Ng∆∞·ª°ng ƒë·ªÉ coi l√† match ho√†n to√†n\n",
    "- **partial_threshold = 0.7**: Ng∆∞·ª°ng ƒë·ªÉ coi l√† partial match\n",
    "- **similarity < 0.7**: Kh√¥ng match, t√≠nh c·∫£ FP v√† FN\n",
    "\n",
    "---\n",
    "\n",
    "## 5. T·ªïng h·ª£p metrics\n",
    "\n",
    "Sau khi t√≠nh metrics cho t·ª´ng record, c√≥ th·ªÉ t√≠nh **Overall Metrics**:\n",
    "\n",
    "```python\n",
    "total_tp = sum([r['tp'] for r in detailed_results])\n",
    "total_fp = sum([r['fp'] for r in detailed_results])\n",
    "total_fn = sum([r['fn'] for r in detailed_results])\n",
    "\n",
    "overall_precision = total_tp / (total_tp + total_fp)\n",
    "overall_recall = total_tp / (total_tp + total_fn)\n",
    "overall_f1 = 2 * (overall_precision * overall_recall) / (overall_precision + overall_recall)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b637e42c",
   "metadata": {},
   "source": [
    "# B√ÅO C√ÅO ƒê√ÅNH GI√Å H·ªÜ TH·ªêNG TEST CASE MODEL\n",
    "\n",
    "## 1. M·ª•c ti√™u c·ªßa h·ªá th·ªëng ƒë√°nh gi√°\n",
    "\n",
    "H·ªá th·ªëng ƒë√°nh gi√° test case do b·∫°n x√¢y d·ª±ng nh·∫±m:\n",
    "\n",
    "1. So s√°nh **Test Case do LLM sinh ra** v·ªõi **Ground Truth (GT)**.\n",
    "2. X√°c ƒë·ªãnh **ƒë√∫ng/sai**, ƒë·ªìng th·ªùi t√≠nh **precision, recall, F1**.\n",
    "3. Cho ph√©p **so s√°nh linh ho·∫°t** (flexible matching) thay v√¨ y√™u c·∫ßu exact match tuy·ªát ƒë·ªëi.\n",
    "4. L∆∞u **chi ti·∫øt t·ª´ng field**, gi√∫p debug model hi·ªáu qu·∫£.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Nguy√™n t·∫Øc ƒë√°nh gi√°\n",
    "\n",
    "### 2.1. Flatten Test Case\n",
    "- T·∫•t c·∫£ c√°c test case ƒë∆∞·ª£c flatten th√†nh d·∫°ng key-value:\n",
    "    - `req_<field>`: input request  \n",
    "    - `exp_<field>`: expected output  \n",
    "    - `res_<field>`: response_mapping  \n",
    "- M·ª•c ti√™u: ƒë·∫£m b·∫£o so s√°nh **t·ª´ng tr∆∞·ªùng d·ªØ li·ªáu** m√† kh√¥ng b·ªã l·ªói nested dict.\n",
    "\n",
    "### 2.2. X·ª≠ l√Ω NULL / ABSENT / N/A\n",
    "- GT c√≥ gi√° tr·ªã `NULL`, `ABSENT` ho·∫∑c `N/A` ‚Üí model ph·∫£i match **exact string ho·∫∑c None/empty**.\n",
    "- N·∫øu model tr·∫£ gi√° tr·ªã kh√°c ‚Üí **FAIL**, kh√¥ng cho partial match.\n",
    "\n",
    "| GT | Model | K·∫øt qu·∫£ |\n",
    "|----|-------|---------|\n",
    "| \"NULL\" | None | ‚úî PASS |\n",
    "| \"NULL\" | \"NULL\" | ‚úî PASS |\n",
    "| \"ABSENT\" | field missing | ‚úî PASS |\n",
    "| \"ABSENT\" | value kh√°c | ‚ùå FAIL |\n",
    "| \"N/A\" | \"N/A\" | ‚úî PASS |\n",
    "\n",
    "### 2.3. So s√°nh d·ªØ li·ªáu s·ªë\n",
    "- N·∫øu l√† s·ªë ‚Üí convert sang float.\n",
    "- Exact match ‚Üí 1.0 similarity.\n",
    "- Sai s·ªë ‚â§ 1% ‚Üí partial match, similarity = 1 - diff.\n",
    "- Sai s·ªë > 1% ‚Üí similarity gi·∫£m.\n",
    "\n",
    "### 2.4. So s√°nh d·ªØ li·ªáu string\n",
    "- Normalize: lowercase, trim, b·ªè multiple spaces.\n",
    "- Fuzzy matching (SequenceMatcher) ‚Üí similarity (0-1).\n",
    "- Threshold 0.85 ‚Üí match, <0.85 ‚Üí partial ho·∫∑c fail.\n",
    "\n",
    "### 2.5. Exact match fallback\n",
    "- N·∫øu kh√¥ng ph·∫£i s·ªë, kh√¥ng ph·∫£i string ‚Üí so s√°nh exact match.\n",
    "- Kh√¥ng match ‚Üí similarity = 0.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. T√≠nh to√°n similarity t·ªïng th·ªÉ\n",
    "- T·ªïng similarity = **trung b√¨nh tr·ªçng s·ªë c·ªßa c√°c field**.\n",
    "- C√≥ th·ªÉ ƒë·∫∑t `field_weights` ƒë·ªÉ ∆∞u ti√™n m·ªôt s·ªë field quan tr·ªçng h∆°n.\n",
    "- `overall_similarity >= threshold` ‚Üí testcase coi l√† **match**.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. X·ª≠ l√Ω c√°c tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát\n",
    "- Model JSON l·ªói (parse l·ªói) ‚Üí t·∫•t c·∫£ test case ‚Üí **FN**.\n",
    "- Test case GT c√≥ m√† Model kh√¥ng c√≥ ‚Üí **FN**.\n",
    "- Test case Model c√≥ m√† GT kh√¥ng c√≥ ‚Üí **FP**.\n",
    "- Partial match (similarity ‚â• 0.7) ‚Üí TP = 0.5, FP = 0.5, FN = 0.5.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Output chi ti·∫øt\n",
    "M·ªói testcase l∆∞u chi ti·∫øt:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"test_case_idx\": 0,\n",
    "    \"status\": \"TP / FP / FN / PARTIAL\",\n",
    "    \"similarity\": 0.87,\n",
    "    \"reason\": \"Match ho·∫∑c l√Ω do fail\",\n",
    "    \"field_details\": {\n",
    "        \"req_userId\": {\n",
    "            \"match\": True,\n",
    "            \"similarity\": 1.0,\n",
    "            \"reason\": \"Strings similar\",\n",
    "            \"gt_value\": \"usr_123\",\n",
    "            \"model_value\": \"usr_123\"\n",
    "        },\n",
    "        \"res_status\": {\n",
    "            \"match\": False,\n",
    "            \"similarity\": 0.0,\n",
    "            \"reason\": \"Model tr·∫£ kh√°c\",\n",
    "            \"gt_value\": \"ACTIVE\",\n",
    "            \"model_value\": \"PENDING\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "---\n",
    "\n",
    "## 6. T√≠nh metrics\n",
    "- TP, FP, FN: d·ª±a tr√™n matching + partial matching.\n",
    "- Precision = TP / (TP + FP)\n",
    "- Recall = TP / (TP + FN)\n",
    "- F1 = 2 * (precision * recall) / (precision + recall)\n",
    "- T√≠nh trung b√¨nh similarity ƒë·ªÉ ƒë√°nh gi√° t·ªïng th·ªÉ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b788e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    \"\"\"Chu·∫©n h√≥a string ƒë·ªÉ so s√°nh: lowercase, b·ªè whitespace th·ª´a\"\"\"\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = str(s).strip().lower()\n",
    "    # B·ªè multiple spaces\n",
    "    s = ' '.join(s.split())\n",
    "    return s\n",
    "\n",
    "def calculate_string_similarity(str1, str2):\n",
    "    \"\"\"T√≠nh similarity gi·ªØa 2 strings (0-1)\"\"\"\n",
    "    if str1 is None and str2 is None:\n",
    "        return 1.0\n",
    "    if str1 is None or str2 is None:\n",
    "        return 0.0\n",
    "    \n",
    "    str1_norm = normalize_string(str1) \n",
    "    str2_norm = normalize_string(str2) \n",
    "    \n",
    "    if str1_norm == str2_norm:\n",
    "        return 1.0\n",
    "    \n",
    "    # S·ª≠ d·ª•ng SequenceMatcher cho fuzzy matching\n",
    "    return SequenceMatcher(None, str1_norm, str2_norm).ratio()\n",
    "\n",
    "def compare_values(gt_val, model_val, field_type=\"auto\"):\n",
    "    \"\"\"\n",
    "    So s√°nh 2 gi√° tr·ªã m·ªôt c√°ch linh ho·∫°t.\n",
    "    \n",
    "    Args:\n",
    "        gt_val: Ground truth value\n",
    "        model_val: Model predicted value\n",
    "        field_type: \"auto\", \"string\", \"number\", \"exact\"\n",
    "    \n",
    "    Returns:\n",
    "        (is_match: bool, similarity: float, reason: str)\n",
    "    \"\"\"\n",
    "    # X·ª≠ l√Ω NULL/ABSENT/N/A\n",
    "    if gt_val in [\"NULL\", \"ABSENT\", \"N/A\"]:\n",
    "        if model_val in [None, \"NULL\", \"ABSENT\", \"N/A\", \"\"]:\n",
    "            return True, 1.0, \"Both are NULL/ABSENT\"\n",
    "        return False, 0.0, f\"GT requires NULL but model has: {model_val}\"\n",
    "    \n",
    "    if model_val is None:\n",
    "        return False, 0.0, \"Model value is None\"\n",
    "    \n",
    "    # Auto-detect type\n",
    "    if field_type == \"auto\":\n",
    "        if isinstance(gt_val, (int, float)) or isinstance(model_val, (int, float)):\n",
    "            field_type = \"number\"\n",
    "        elif isinstance(gt_val, str) and isinstance(model_val, str):\n",
    "            field_type = \"string\"\n",
    "        else:\n",
    "            field_type = \"exact\"\n",
    "    \n",
    "    # So s√°nh s·ªë\n",
    "    if field_type == \"number\":\n",
    "        try:\n",
    "            gt_num = float(gt_val)\n",
    "            model_num = float(model_val)\n",
    "            if gt_num == model_num:\n",
    "                return True, 1.0, \"Numbers match exactly\"\n",
    "            # Cho ph√©p sai s·ªë nh·ªè (1%)\n",
    "            diff = abs(gt_num - model_num) / max(abs(gt_num), 1)\n",
    "            if diff < 0.01:\n",
    "                return True, 1.0 - diff, \"Numbers match approximately\"\n",
    "            return False, 1.0 - min(diff, 1.0), f\"Numbers differ: {gt_num} vs {model_num}\"\n",
    "        except (ValueError, TypeError):\n",
    "            # Kh√¥ng ph·∫£i s·ªë, so s√°nh nh∆∞ string\n",
    "            field_type = \"string\"\n",
    "    \n",
    "    # So s√°nh string\n",
    "    if field_type == \"string\":\n",
    "        similarity = calculate_string_similarity(gt_val, model_val)\n",
    "        # Threshold: >= 0.85 ƒë∆∞·ª£c coi l√† match\n",
    "        threshold = 0.85\n",
    "        if similarity >= threshold:\n",
    "            return True, similarity, f\"Strings similar (similarity: {similarity:.2f})\"\n",
    "        return False, similarity, f\"Strings differ (similarity: {similarity:.2f})\"\n",
    "    \n",
    "    # Exact match (fallback)\n",
    "    if gt_val == model_val:\n",
    "        return True, 1.0, \"Exact match\"\n",
    "    return False, 0.0, f\"Values differ: {gt_val} vs {model_val}\"\n",
    "\n",
    "def flatten_case(tc):\n",
    "    \"\"\"Flatten test case ƒë·ªÉ so s√°nh\"\"\"\n",
    "    flat = {}\n",
    "    \n",
    "    flat[\"test_case\"] = tc.get(\"test_case\", \"\")\n",
    "    \n",
    "    # request_mapping\n",
    "    for k, v in tc.get(\"request_mapping\", {}).items():\n",
    "        flat[f\"req_{k}\"] = v\n",
    "    \n",
    "    # expected_output\n",
    "    for k, v in tc.get(\"expected_output\", {}).items():\n",
    "        if k == \"response_mapping\":\n",
    "            # flatten response_mapping\n",
    "            for kk, vv in v.items():\n",
    "                flat[f\"res_{kk}\"] = vv\n",
    "        else:\n",
    "            flat[f\"exp_{k}\"] = v\n",
    "    \n",
    "    return flat\n",
    "\n",
    "def compare_cases(gt_case, model_case, similarity_threshold=0.85, field_weights=None):\n",
    "    \"\"\"\n",
    "    So s√°nh 2 test cases m·ªôt c√°ch linh ho·∫°t.\n",
    "    \n",
    "    Args:\n",
    "        gt_case: Ground truth test case\n",
    "        model_case: Model predicted test case\n",
    "        similarity_threshold: Ng∆∞·ª°ng similarity t·ªïng th·ªÉ ƒë·ªÉ coi l√† match (0-1)\n",
    "        field_weights: Dict v·ªõi weights cho t·ª´ng field (optional)\n",
    "    \n",
    "    Returns:\n",
    "        (is_match: bool, overall_similarity: float, details: dict)\n",
    "    \"\"\"\n",
    "    if field_weights is None:\n",
    "        field_weights = {}\n",
    "    \n",
    "    gt_flat = flatten_case(gt_case)\n",
    "    model_flat = flatten_case(model_case)\n",
    "    \n",
    "    total_similarity = 0.0\n",
    "    total_weight = 0.0\n",
    "    field_details = {}\n",
    "    all_match = True\n",
    "    \n",
    "    # So s√°nh t·ª´ng field\n",
    "    for key in gt_flat:\n",
    "        gt_val = gt_flat[key]\n",
    "        model_val = model_flat.get(key, None)\n",
    "        \n",
    "        # X√°c ƒë·ªãnh field type\n",
    "        field_type = \"auto\"\n",
    "        if key == \"exp_statuscode\" or \"statuscode\" in key.lower():\n",
    "            field_type = \"number\"\n",
    "        elif \"test_case\" in key:\n",
    "            field_type = \"string\"\n",
    "        \n",
    "        # So s√°nh\n",
    "        is_match, similarity, reason = compare_values(gt_val, model_val, field_type)\n",
    "        \n",
    "        weight = field_weights.get(key, 1.0)\n",
    "        total_similarity += similarity * weight\n",
    "        total_weight += weight\n",
    "        \n",
    "        field_details[key] = {\n",
    "            'match': is_match,\n",
    "            'similarity': similarity,\n",
    "            'reason': reason,\n",
    "            'gt_value': gt_val,\n",
    "            'model_value': model_val\n",
    "        }\n",
    "        \n",
    "        if not is_match:\n",
    "            all_match = False\n",
    "    \n",
    "    # T√≠nh overall similarity\n",
    "    if total_weight > 0:\n",
    "        overall_similarity = total_similarity / total_weight\n",
    "    else:\n",
    "        overall_similarity = 0.0\n",
    "    \n",
    "    # Ki·ªÉm tra c√°c field model c√≥ m√† GT kh√¥ng c√≥ (kh√¥ng t√≠nh v√†o similarity nh∆∞ng ghi nh·∫≠n)\n",
    "    extra_fields = set(model_flat.keys()) - set(gt_flat.keys())\n",
    "    if extra_fields:\n",
    "        field_details['_extra_fields'] = list(extra_fields)\n",
    "    \n",
    "    # Quy·∫øt ƒë·ªãnh match d·ª±a tr√™n threshold\n",
    "    final_match = overall_similarity >= similarity_threshold\n",
    "    \n",
    "    return final_match, overall_similarity, field_details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591ae536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 6b. C·∫¨P NH·∫¨T H√ÄM calculate_testcase_metrics V·ªöI FUZZY MATCHING\n",
    "# ================================================================\n",
    "\n",
    "def calculate_testcase_metrics_flexible(gt_json, model_json, similarity_threshold=0.85):\n",
    "    \"\"\"\n",
    "    T√≠nh precision, recall, F1 cho t·ª´ng test case v·ªõi Fuzzy Matching linh ho·∫°t.\n",
    "    \n",
    "    Logic:\n",
    "    - V·ªõi m·ªói test case GT: so s√°nh v·ªõi T·∫§T C·∫¢ test cases Model\n",
    "    - Ch·ªçn Model case c√≥ similarity cao nh·∫•t\n",
    "    - N·∫øu similarity >= threshold ‚Üí match (TP)\n",
    "    - N·∫øu similarity < threshold ‚Üí GT ƒë√≥ l√† FN\n",
    "    - Model cases kh√¥ng ƒë∆∞·ª£c gh√©p ‚Üí FP\n",
    "    \n",
    "    Args:\n",
    "        gt_json: Ground truth JSON\n",
    "        model_json: Model prediction JSON\n",
    "        similarity_threshold: Ng∆∞·ª°ng similarity ƒë·ªÉ coi l√† match (default: 0.85)\n",
    "    \n",
    "    Returns:\n",
    "        dict v·ªõi keys: 'tp', 'fp', 'fn', 'precision', 'recall', 'f1', 'details'\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'tp': 0.0,\n",
    "        'fp': 0.0,\n",
    "        'fn': 0.0,\n",
    "        'precision': 0.0,\n",
    "        'recall': 0.0,\n",
    "        'f1': 0.0,\n",
    "        'details': [],\n",
    "        'avg_similarity': 0.0\n",
    "    }\n",
    "    \n",
    "    # N·∫øu model JSON l·ªói ‚Üí t·∫•t c·∫£ l√† FN\n",
    "    if model_json is None:\n",
    "        gt_cases = gt_json.get(\"basic_validation\", []) if gt_json else []\n",
    "        result['fn'] = len(gt_cases)\n",
    "        for idx, gt_case in enumerate(gt_cases):\n",
    "            result['details'].append({\n",
    "                'test_case_idx': idx,\n",
    "                'status': 'FN',\n",
    "                'reason': 'Model JSON is None',\n",
    "                'similarity': 0.0,\n",
    "                'matched_model_idx': None\n",
    "            })\n",
    "        return result\n",
    "    \n",
    "    gt_cases = gt_json.get(\"basic_validation\", []) if gt_json else []\n",
    "    model_cases = model_json.get(\"basic_validation\", []) if model_json else []\n",
    "    \n",
    "    # Kh·ªüi t·∫°o: t·∫•t c·∫£ Model cases ch∆∞a ƒë∆∞·ª£c match\n",
    "    model_matched = [False] * len(model_cases)\n",
    "    total_similarity = 0.0\n",
    "    matched_count = 0\n",
    "    \n",
    "    # V·ªõi m·ªói GT case: t√¨m Model case c√≥ similarity cao nh·∫•t (ch∆∞a ƒë∆∞·ª£c match)\n",
    "    for gt_idx, gt_case in enumerate(gt_cases):\n",
    "        best_similarity = 0.0\n",
    "        best_model_idx = None\n",
    "        best_field_details = None\n",
    "        best_is_match = False\n",
    "        \n",
    "        # So s√°nh v·ªõi t·∫•t c·∫£ Model cases (ch·ªâ x√©t c√°c case ch∆∞a ƒë∆∞·ª£c match)\n",
    "        for model_idx, model_case in enumerate(model_cases):\n",
    "            # B·ªè qua Model case ƒë√£ ƒë∆∞·ª£c match\n",
    "            if model_matched[model_idx]:\n",
    "                continue\n",
    "                \n",
    "            # T√≠nh similarity\n",
    "            is_match, similarity, field_details = compare_cases(\n",
    "                gt_case, model_case, \n",
    "                similarity_threshold=similarity_threshold\n",
    "            )\n",
    "            \n",
    "            # Ch·ªçn Model case c√≥ similarity cao nh·∫•t\n",
    "            if similarity > best_similarity:\n",
    "                best_similarity = similarity\n",
    "                best_model_idx = model_idx\n",
    "                best_field_details = field_details\n",
    "                best_is_match = is_match\n",
    "        \n",
    "        # T·∫°o detail cho GT case n√†y\n",
    "        detail = {\n",
    "            'test_case_idx': gt_idx,\n",
    "            'status': None,\n",
    "            'reason': None,\n",
    "            'similarity': best_similarity,\n",
    "            'field_details': best_field_details,\n",
    "            'matched_model_idx': best_model_idx\n",
    "        }\n",
    "        \n",
    "        # Quy·∫øt ƒë·ªãnh match d·ª±a tr√™n threshold\n",
    "        if best_model_idx is not None and best_similarity >= similarity_threshold:\n",
    "            # Match th√†nh c√¥ng ‚Üí TP\n",
    "            result['tp'] += 1\n",
    "            detail['status'] = 'TP'\n",
    "            detail['reason'] = f'Match (similarity: {best_similarity:.4f})'\n",
    "            model_matched[best_model_idx] = True\n",
    "            total_similarity += best_similarity\n",
    "            matched_count += 1\n",
    "        else:\n",
    "            # Kh√¥ng match ƒë·ªß t·ªët ‚Üí FN\n",
    "            result['fn'] += 1\n",
    "            if best_model_idx is None:\n",
    "                detail['status'] = 'FN'\n",
    "                detail['reason'] = 'No available Model case to match (all already matched)'\n",
    "            else:\n",
    "                detail['status'] = 'FN'\n",
    "                detail['reason'] = f'No match found (best similarity: {best_similarity:.4f} < {similarity_threshold})'\n",
    "            # V·∫´n ghi nh·∫≠n similarity ƒë·ªÉ ph√¢n t√≠ch\n",
    "            if best_similarity > 0:\n",
    "                total_similarity += best_similarity\n",
    "                matched_count += 1\n",
    "        \n",
    "        result['details'].append(detail)\n",
    "    \n",
    "    # Model cases kh√¥ng ƒë∆∞·ª£c gh√©p ‚Üí FP\n",
    "    for model_idx, is_matched in enumerate(model_matched):\n",
    "        if not is_matched:\n",
    "            result['fp'] += 1\n",
    "            result['details'].append({\n",
    "                'test_case_idx': None,  # Kh√¥ng c√≥ GT t∆∞∆°ng ·ª©ng\n",
    "                'status': 'FP',\n",
    "                'reason': f'Model test case #{model_idx} not matched with any GT',\n",
    "                'similarity': 0.0,\n",
    "                'field_details': None,\n",
    "                'matched_model_idx': model_idx\n",
    "            })\n",
    "    \n",
    "    # T√≠nh trung b√¨nh similarity\n",
    "    if matched_count > 0:\n",
    "        result['avg_similarity'] = total_similarity / matched_count\n",
    "    \n",
    "    # T√≠nh precision, recall, F1\n",
    "    tp = result['tp']\n",
    "    fp = result['fp']\n",
    "    fn = result['fn']\n",
    "    \n",
    "    # Precision = TP / (TP + FP)\n",
    "    if tp + fp > 0:\n",
    "        result['precision'] = tp / (tp + fp)\n",
    "    else:\n",
    "        result['precision'] = 0.0\n",
    "    \n",
    "    # Recall = TP / (TP + FN)\n",
    "    if tp + fn > 0:\n",
    "        result['recall'] = tp / (tp + fn)\n",
    "    else:\n",
    "        result['recall'] = 0.0\n",
    "    \n",
    "    # F1 = 2 * (precision * recall) / (precision + recall)\n",
    "    if result['precision'] + result['recall'] > 0:\n",
    "        result['f1'] = 2 * (result['precision'] * result['recall']) / (result['precision'] + result['recall'])\n",
    "    else:\n",
    "        result['f1'] = 0.0\n",
    "    \n",
    "    return result\n",
    "\n",
    "# S·ª≠ d·ª•ng h√†m m·ªõi thay cho h√†m c≈©\n",
    "# calculate_testcase_metrics = calculate_testcase_metrics_flexible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832bd83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# THAY TH·∫æ H√ÄM C≈® B·∫∞NG H√ÄM M·ªöI (LINH HO·∫†T)\n",
    "# ================================================================\n",
    "\n",
    "# Uncomment d√≤ng d∆∞·ªõi ƒë·ªÉ s·ª≠ d·ª•ng h√†m so s√°nh linh ho·∫°t\n",
    "calculate_testcase_metrics = calculate_testcase_metrics_flexible\n",
    "\n",
    "print(\"‚úÖ ƒê√£ chuy·ªÉn sang s·ª≠ d·ª•ng Fuzzy Matching linh ho·∫°t!\")\n",
    "print(\"   - V·ªõi m·ªói GT test case: so s√°nh v·ªõi T·∫§T C·∫¢ Model test cases\")\n",
    "print(\"   - Ch·ªçn Model case c√≥ similarity cao nh·∫•t\")\n",
    "print(\"   - N·∫øu similarity >= threshold (0.85) ‚Üí match (TP)\")\n",
    "print(\"   - N·∫øu similarity < threshold ‚Üí GT ƒë√≥ l√† FN\")\n",
    "print(\"   - Model cases kh√¥ng ƒë∆∞·ª£c gh√©p ‚Üí FP\")\n",
    "print(\"   - Fuzzy matching cho strings + field matching\")\n",
    "print(\"   - T√≠nh similarity score chi ti·∫øt cho t·ª´ng field\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0130aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 7. ƒê√ÅNH GI√Å T·∫§T C·∫¢ RECORDS V√Ä T√çNH METRICS\n",
    "# ================================================================\n",
    "\n",
    "# T√≠nh metrics cho t·ª´ng record\n",
    "detailed_results = []\n",
    "for idx in range(len(gt_df)):\n",
    "    gt_json = gt_df.iloc[idx][\"testcases\"]\n",
    "    model_json = pre_df.iloc[idx][\"testcases\"]\n",
    "    \n",
    "    metrics = calculate_testcase_metrics(gt_json, model_json)\n",
    "    metrics['record_idx'] = idx\n",
    "    metrics['record_id'] = gt_df.iloc[idx].get('id', idx)\n",
    "    detailed_results.append(metrics)\n",
    "\n",
    "# Th√™m metrics v√†o dataframe\n",
    "pre_df['metrics'] = detailed_results\n",
    "pre_df['precision'] = [r['precision'] for r in detailed_results]\n",
    "pre_df['recall'] = [r['recall'] for r in detailed_results]\n",
    "pre_df['f1'] = [r['f1'] for r in detailed_results]\n",
    "pre_df['tp'] = [r['tp'] for r in detailed_results]\n",
    "pre_df['fp'] = [r['fp'] for r in detailed_results]\n",
    "pre_df['fn'] = [r['fn'] for r in detailed_results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd9d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 8. HI·ªÇN TH·ªä K·∫æT QU·∫¢ T·ªîNG QUAN\n",
    "# ================================================================\n",
    "\n",
    "# T√≠nh t·ªïng TP, FP, FN\n",
    "total_tp = sum([r['tp'] for r in detailed_results])\n",
    "total_fp = sum([r['fp'] for r in detailed_results])\n",
    "total_fn = sum([r['fn'] for r in detailed_results])\n",
    "\n",
    "# T√≠nh overall precision, recall, F1\n",
    "overall_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0\n",
    "overall_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0.0\n",
    "overall_f1 = 2 * (overall_precision * overall_recall) / (overall_precision + overall_recall) if (overall_precision + overall_recall) > 0 else 0.0\n",
    "\n",
    "# T√≠nh trung b√¨nh precision, recall, F1\n",
    "avg_precision = pre_df['precision'].mean()\n",
    "avg_recall = pre_df['recall'].mean()\n",
    "avg_f1 = pre_df['f1'].mean()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"K·∫æT QU·∫¢ ƒê√ÅNH GI√Å T·ªîNG QUAN\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìä S·ªë l∆∞·ª£ng test cases:\")\n",
    "print(f\"   - True Positives (TP):  {total_tp}\")\n",
    "print(f\"   - False Positives (FP): {total_fp}\")\n",
    "print(f\"   - False Negatives (FN): {total_fn}\")\n",
    "print(f\"   - T·ªïng GT test cases:   {total_tp + total_fn}\")\n",
    "print(f\"   - T·ªïng Pred test cases: {total_tp + total_fp}\")\n",
    "\n",
    "print(f\"\\nüìà Overall Metrics (t√≠nh t·ª´ t·ªïng TP/FP/FN):\")\n",
    "print(f\"   - Precision: {overall_precision:.4f}\")\n",
    "print(f\"   - Recall:    {overall_recall:.4f}\")\n",
    "print(f\"   - F1 Score:  {overall_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nüìä Average Metrics (trung b√¨nh t·ª´ng record):\")\n",
    "print(f\"   - Precision: {avg_precision:.4f}\")\n",
    "print(f\"   - Recall:    {avg_recall:.4f}\")\n",
    "print(f\"   - F1 Score:  {avg_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nüìã S·ªë records:\")\n",
    "print(f\"   - T·ªïng s·ªë records: {len(pre_df)}\")\n",
    "print(f\"   - Records c√≥ JSON h·ª£p l·ªá: {pre_df['testcases'].notna().sum()}\")\n",
    "print(f\"   - Records c√≥ JSON l·ªói: {pre_df['testcases'].isna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02363b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 9. XEM CHI TI·∫æT T·ª™NG RECORD\n",
    "# ================================================================\n",
    "\n",
    "# Hi·ªÉn th·ªã m·ªôt s·ªë records v·ªõi metrics\n",
    "display_cols = ['id', 'precision', 'recall', 'f1', 'tp', 'fp', 'fn']\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CHI TI·∫æT M·ªòT S·ªê RECORDS (top 10)\")\n",
    "print(\"=\" * 60)\n",
    "print(pre_df[display_cols].head(10).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28011be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 10. XEM CHI TI·∫æT T·ª™NG TEST CASE TRONG 1 RECORD\n",
    "# ================================================================\n",
    "\n",
    "def show_record_details(record_idx):\n",
    "    \"\"\"\n",
    "    Hi·ªÉn th·ªã chi ti·∫øt t·ª´ng test case trong 1 record.\n",
    "    \"\"\"\n",
    "    if record_idx >= len(detailed_results):\n",
    "        print(f\"Record index {record_idx} kh√¥ng t·ªìn t·∫°i!\")\n",
    "        return\n",
    "    \n",
    "    result = detailed_results[record_idx]\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"CHI TI·∫æT RECORD #{record_idx} (ID: {result['record_id']})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nüìä Metrics:\")\n",
    "    print(f\"   - Precision: {result['precision']:.4f}\")\n",
    "    print(f\"   - Recall:    {result['recall']:.4f}\")\n",
    "    print(f\"   - F1 Score:  {result['f1']:.4f}\")\n",
    "    print(f\"   - TP: {result['tp']}, FP: {result['fp']}, FN: {result['fn']}\")\n",
    "    \n",
    "    print(f\"\\nüìã Chi ti·∫øt t·ª´ng test case:\")\n",
    "    for detail in result['details']:\n",
    "        status_emoji = {\n",
    "            'TP': '‚úÖ',\n",
    "            'FP': '‚ùå',\n",
    "            'FN': '‚ö†Ô∏è',\n",
    "            'FP+FN': '‚ùå‚ö†Ô∏è',\n",
    "            'PARTIAL': 'üü°'\n",
    "        }\n",
    "        emoji = status_emoji.get(detail['status'], '‚ùì')\n",
    "        \n",
    "        # Hi·ªÉn th·ªã th√¥ng tin match\n",
    "        if detail.get('test_case_idx') is not None:\n",
    "            match_info = \"\"\n",
    "            if detail.get('matched_model_idx') is not None:\n",
    "                match_info = f\" ‚Üí Matched with Model case #{detail['matched_model_idx']}\"\n",
    "            similarity_info = f\" (similarity: {detail.get('similarity', 0.0):.4f})\" if detail.get('similarity', 0) > 0 else \"\"\n",
    "            print(f\"   {emoji} GT Test case #{detail['test_case_idx']}: {detail['status']} - {detail['reason']}{match_info}{similarity_info}\")\n",
    "        else:\n",
    "            # FP case (Model case kh√¥ng c√≥ GT t∆∞∆°ng ·ª©ng)\n",
    "            print(f\"   {emoji} Model Test case #{detail.get('matched_model_idx', '?')}: {detail['status']} - {detail['reason']}\")\n",
    "\n",
    "# V√≠ d·ª•: xem chi ti·∫øt record ƒë·∫ßu ti√™n\n",
    "show_record_details(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910c9f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 11. PH√ÇN T√çCH THEO NH√ìM (n·∫øu c√≥ th√¥ng tin ph√¢n lo·∫°i)\n",
    "# ================================================================\n",
    "\n",
    "# Ph√¢n t√≠ch theo domain (n·∫øu c√≥)\n",
    "if 'domain' in pre_df.columns:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PH√ÇN T√çCH THEO DOMAIN\")\n",
    "    print(\"=\" * 60)\n",
    "    domain_stats = pre_df.groupby('domain').agg({\n",
    "        'precision': 'mean',\n",
    "        'recall': 'mean',\n",
    "        'f1': 'mean',\n",
    "        'tp': 'sum',\n",
    "        'fp': 'sum',\n",
    "        'fn': 'sum'\n",
    "    }).round(4)\n",
    "    print(domain_stats)\n",
    "\n",
    "# Ph√¢n t√≠ch theo api_functionality (n·∫øu c√≥)\n",
    "if 'api_functionality' in pre_df.columns:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PH√ÇN T√çCH THEO API FUNCTIONALITY\")\n",
    "    print(\"=\" * 60)\n",
    "    func_stats = pre_df.groupby('api_functionality').agg({\n",
    "        'precision': 'mean',\n",
    "        'recall': 'mean',\n",
    "        'f1': 'mean',\n",
    "        'id': 'count'\n",
    "    }).round(4)\n",
    "    func_stats.columns = ['avg_precision', 'avg_recall', 'avg_f1', 'count']\n",
    "    print(func_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea422f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 13. V·∫º BI·ªÇU ƒê·ªí PH√ÇN T√çCH (Optional)\n",
    "# ================================================================\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    # T·∫°o figure v·ªõi subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Ph√¢n t√≠ch Precision, Recall, F1 Score', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Distribution of Precision, Recall, F1\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.hist(pre_df['precision'].dropna(), bins=20, alpha=0.7, label='Precision', color='blue')\n",
    "    ax1.hist(pre_df['recall'].dropna(), bins=20, alpha=0.7, label='Recall', color='green')\n",
    "    ax1.hist(pre_df['f1'].dropna(), bins=20, alpha=0.7, label='F1', color='red')\n",
    "    ax1.set_xlabel('Score')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.set_title('Distribution of Metrics')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Scatter plot: Precision vs Recall\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.scatter(pre_df['recall'], pre_df['precision'], alpha=0.6, s=50)\n",
    "    ax2.set_xlabel('Recall')\n",
    "    ax2.set_ylabel('Precision')\n",
    "    ax2.set_title('Precision vs Recall')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xlim([-0.05, 1.05])\n",
    "    ax2.set_ylim([-0.05, 1.05])\n",
    "    \n",
    "    # 3. Bar chart: TP, FP, FN totals\n",
    "    ax3 = axes[1, 0]\n",
    "    categories = ['TP', 'FP', 'FN']\n",
    "    values = [total_tp, total_fp, total_fn]\n",
    "    colors = ['green', 'red', 'orange']\n",
    "    ax3.bar(categories, values, color=colors, alpha=0.7)\n",
    "    ax3.set_ylabel('Count')\n",
    "    ax3.set_title('Total TP, FP, FN')\n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "    for i, v in enumerate(values):\n",
    "        ax3.text(i, v, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 4. Metrics comparison\n",
    "    ax4 = axes[1, 1]\n",
    "    metrics_names = ['Overall\\nPrecision', 'Overall\\nRecall', 'Overall\\nF1', \n",
    "                     'Average\\nPrecision', 'Average\\nRecall', 'Average\\nF1']\n",
    "    metrics_values = [overall_precision, overall_recall, overall_f1,\n",
    "                      avg_precision, avg_recall, avg_f1]\n",
    "    colors_metrics = ['blue', 'green', 'red', 'lightblue', 'lightgreen', 'pink']\n",
    "    bars = ax4.bar(metrics_names, metrics_values, color=colors_metrics, alpha=0.7)\n",
    "    ax4.set_ylabel('Score')\n",
    "    ax4.set_title('Overall vs Average Metrics')\n",
    "    ax4.set_ylim([0, 1.1])\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "    for bar, val in zip(bars, metrics_values):\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{val:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./dataset_eval/metrics_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì ph√¢n t√≠ch v√†o: ./dataset_eval/metrics_analysis.png\")\n",
    "    plt.show()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Matplotlib ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. B·ªè qua ph·∫ßn v·∫Ω bi·ªÉu ƒë·ªì.\")\n",
    "    print(\"   C√≥ th·ªÉ c√†i ƒë·∫∑t b·∫±ng: pip install matplotlib\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è L·ªói khi v·∫Ω bi·ªÉu ƒë·ªì: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6bf01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 12. L∆ØU K·∫æT QU·∫¢ CHI TI·∫æT\n",
    "# ================================================================\n",
    "\n",
    "# T·∫°o dataframe chi ti·∫øt t·ª´ng test case\n",
    "testcase_details = []\n",
    "for record_result in detailed_results:\n",
    "    record_id = record_result['record_id']\n",
    "    for detail in record_result['details']:\n",
    "        testcase_details.append({\n",
    "            'record_id': record_id,\n",
    "            'test_case_idx': detail['test_case_idx'],\n",
    "            'status': detail['status'],\n",
    "            'reason': detail['reason']\n",
    "        })\n",
    "\n",
    "testcase_df = pd.DataFrame(testcase_details)\n",
    "\n",
    "# L∆∞u k·∫øt qu·∫£\n",
    "output_file = \"./dataset_eval/evaluation_results.csv\"\n",
    "pre_df[['id', 'precision', 'recall', 'f1', 'tp', 'fp', 'fn']].to_csv(output_file, index=False)\n",
    "print(f\"\\n‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ t·ªïng quan v√†o: {output_file}\")\n",
    "\n",
    "# L∆∞u chi ti·∫øt t·ª´ng test case\n",
    "testcase_output_file = \"./dataset_eval/testcase_details.csv\"\n",
    "testcase_df.to_csv(testcase_output_file, index=False)\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u chi ti·∫øt t·ª´ng test case v√†o: {testcase_output_file}\")\n",
    "\n",
    "print(f\"\\nüìä T·ªïng s·ªë test cases ƒë∆∞·ª£c ƒë√°nh gi√°: {len(testcase_df)}\")\n",
    "print(f\"   - TP: {len(testcase_df[testcase_df['status'] == 'TP'])}\")\n",
    "print(f\"   - FP: {len(testcase_df[testcase_df['status'] == 'FP'])}\")\n",
    "print(f\"   - FN: {len(testcase_df[testcase_df['status'] == 'FN'])}\")\n",
    "print(f\"   - FP+FN: {len(testcase_df[testcase_df['status'] == 'FP+FN'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2107c248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aa0736",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
